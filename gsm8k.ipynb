{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pip\n",
    "def import_or_install(package):\n",
    "    try:\n",
    "        __import__(package)\n",
    "    except ImportError:\n",
    "        pip.main(['install', package])  \n",
    "\n",
    "import_or_install('datasets')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import adalflow as adal\n",
    "import re\n",
    "import os\n",
    "import json\n",
    "# Development of the Adal Component\n",
    "from typing import Any\n",
    "from adalflow.eval import AnswerMatchAcc\n",
    "from adalflow.datasets import Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "ds = load_dataset(\"openai/gsm8k\", \"main\")\n",
    "print(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into train into validation, Test is already split\n",
    "train_test_split = ds['train'].train_test_split(test_size=0.4, seed=42, shuffle=True,)\n",
    "train_data = train_test_split['train']\n",
    "test_data = train_test_split['test']\n",
    "\n",
    "# Making test data into validation data\n",
    "val_data = ds['test']\n",
    "\n",
    "print(len(train_data))\n",
    "print(len(val_data))\n",
    "print(len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the dataset for the adalflow format\n",
    "from adalflow.utils import Dataset\n",
    "from adalflow.datasets import Example\n",
    "from adalflow.utils.data import subset_dataset\n",
    "import uuid\n",
    "class GSM8K_Train(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        id=str(uuid.uuid4())\n",
    "        return Example(id=index, question=self.data[index]['question'], answer=self.data[index]['answer'])\n",
    "\n",
    "class GSM8K_Test(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        id=str(uuid.uuid4())\n",
    "        return Example(id=index, question=self.data[index]['question'], answer=self.data[index]['answer'])\n",
    "    \n",
    "class GSM8K_Val(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        id=str(uuid.uuid4())\n",
    "        return Example(id=index, question=self.data[index]['question'], answer=self.data[index]['answer'])\n",
    "    \n",
    "train_dataset = GSM8K_Train(ds['train'])\n",
    "test_dataset = GSM8K_Test(ds['test'])\n",
    "val_dataset = GSM8K_Val(ds['test'])\n",
    "\n",
    "NUM_TRAIN_SAMPLES = 1000\n",
    "NUM_TEST_SAMPLES = 1000\n",
    "NUM_VAL_SAMPLES = 1000\n",
    "\n",
    "train_dataset = subset_dataset(train_dataset, NUM_TRAIN_SAMPLES)\n",
    "test_dataset = subset_dataset(test_dataset, NUM_TEST_SAMPLES)\n",
    "val_dataset = subset_dataset(val_dataset, NUM_VAL_SAMPLES)\n",
    "\n",
    "print(len(train_dataset))\n",
    "print(len(test_dataset))\n",
    "print(len(val_dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset Preparation Completed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "@adal.func_to_data_component\n",
    "def parse_integer_answer(answer: str):\n",
    "    \"\"\"A function that parses the last integer from a string using regular expressions.\"\"\"\n",
    "    try:\n",
    "        # Use regular expression to find all sequences of digits\n",
    "        numbers = re.findall(r\"\\d+\", answer)\n",
    "        if numbers:\n",
    "            # Get the last number found\n",
    "            answer = int(numbers[-1])\n",
    "        else:\n",
    "            answer = -1\n",
    "    except ValueError:\n",
    "        answer = -1\n",
    "\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the few shot template\n",
    "FEW_SHOT_TEMPLATE = r\"\"\"<START_OF_SYSTEM_PROMPT>\n",
    "{{system_prompt}}\n",
    "{# Few shot demos #}\n",
    "{% if few_shot_demos is not none %}\n",
    "Here are some examples:\n",
    "{{few_shot_demos}}\n",
    "{% endif %}\n",
    "<END_OF_SYSTEM_PROMPT>\n",
    "<START_OF_USER>\n",
    "{{input_str}}\n",
    "<END_OF_USER>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from adalflow import GoogleGenAIClient\n",
    "main_model_client =GoogleGenAIClient(api_key=\"<your_api_key>\")\n",
    "main_model_kwargs = {\n",
    "        \"model\":\"gemini-1.5-flash-002\",\n",
    "        \"temperature\":0.6,\n",
    "        \"top_p\":0.95,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making the task Pipeline\n",
    "from adalflow import Parameter, ParameterType\n",
    "\n",
    "class GSM8K_Task_Pipeline(adal.Component):\n",
    "    def __init__(self, model_client: adal.ModelClient, model_kwargs: dict):\n",
    "        super().__init__()\n",
    "        system_prompt = adal.Parameter(\n",
    "            data=\"You will answer a reasoning question. Think step by step. The last line of your response should be of the following format: 'Answer: $VALUE' where VALUE is a numerical value.\",\n",
    "            role_desc=\"To give task instruction to the language model in the system prompt\",\n",
    "            requires_opt=False,\n",
    "            param_type=ParameterType.PROMPT,\n",
    "        )\n",
    "\n",
    "        few_shot_demos = adal.Parameter(\n",
    "            data=None,\n",
    "            role_desc=\"To give few shot examples to the language model in the system prompt\",\n",
    "            requires_opt=False,\n",
    "            param_type=ParameterType.DEMOS,\n",
    "        )\n",
    "\n",
    "        self.llm_counter = adal.Generator(\n",
    "            model_client=model_client,\n",
    "            model_kwargs=model_kwargs,\n",
    "            template=FEW_SHOT_TEMPLATE,\n",
    "            prompt_kwargs={\"system_prompt\":system_prompt, \"few_shot_demos\":few_shot_demos},\n",
    "            output_processors=parse_integer_answer,\n",
    "            cache_path=None,\n",
    "            use_cache=False,\n",
    "            name=\"llm_counter\",\n",
    "        )\n",
    "\n",
    "    def call(self, question: str,id: str):\n",
    "        output= self.llm_counter(prompt_kwargs={\"input_str\": question},id=id)\n",
    "        return output\n",
    "    \n",
    "\n",
    "# Testing of the task\n",
    "task = GSM8K_Task_Pipeline(model_client=main_model_client, model_kwargs=main_model_kwargs)\n",
    "\n",
    "try:    \n",
    "    for i in val_dataset:\n",
    "        print(task(question=i.question,id=i.id))\n",
    "        break\n",
    "    for i in train_dataset:\n",
    "        print(task(question=i.question,id=i.id))\n",
    "        break\n",
    "    for i in test_dataset:\n",
    "        print(task(question=i.question,id=i.id))\n",
    "        break\n",
    "\n",
    "    print(\"Successfully tested the task\")\n",
    "except Exception as e:\n",
    "    print(\"Failed to test the task : Error : \",e)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class GSM8K_Counter_Component(adal.AdalComponent):\n",
    "    def __init__(self, model_client: adal.ModelClient, model_kwargs: dict):\n",
    "        task = GSM8K_Task_Pipeline(model_client=model_client, model_kwargs=model_kwargs)\n",
    "        eval_func = AnswerMatchAcc(type=\"exact_match\").compute_single_item\n",
    "        super().__init__(task=task, eval_fn=eval_func)\n",
    "\n",
    "    def prepare_task(self, sample:Example,):\n",
    "        return self.task.call, {\"question\": sample.question, \"id\": sample.id}\n",
    "    \n",
    "    def prepare_eval(self, sample: Example, y_pred: adal.GeneratorOutput) -> float:\n",
    "        y_label = -1\n",
    "        if (y_pred is not None and y_pred.data is not None):  # if y_pred and y_pred.data: might introduce bug when the data is 0\n",
    "            y_label = y_pred.data\n",
    "        y_gt = parse_integer_answer(sample.answer)\n",
    "        return self.eval_fn, {\"y\": y_label, \"y_gt\": y_gt}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict\n",
    "from adalflow.utils.data import Subset\n",
    "\n",
    "def diagnose(\n",
    "    model_client: adal.ModelClient,\n",
    "    model_kwargs: Dict,\n",
    "    dataset: Subset,\n",
    "    split: str,\n",
    ") -> Dict:\n",
    "\n",
    "    adal_component = GSM8K_Counter_Component(model_client=model_client, model_kwargs=model_kwargs)\n",
    "    trainer = adal.Trainer(adaltask=adal_component,debug=False,)\n",
    "    trainer.diagnose(dataset=dataset, split=split)\n",
    "\n",
    "diagnose(model_client=main_model_client, model_kwargs=main_model_kwargs, dataset=train_dataset, split=\"TRAINING\")\n",
    "diagnose(model_client=main_model_client, model_kwargs=main_model_kwargs, dataset=val_dataset, split=\"VALIDATION\")\n",
    "diagnose(model_client=main_model_client, model_kwargs=main_model_kwargs, dataset=test_dataset, split=\"TESTING\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Backward Training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initlize the backward training\n",
    "from adalflow.core import BackwardEngine\n",
    "backward_engine=BackwardEngine(\n",
    "            model_client=GoogleGenAIClient(api_key=\"<your_api_key>\"),\n",
    "            model_kwargs={\n",
    "                \"model\": \"gemini-1.5-pro\",\n",
    "                \"temperature\": 0.6,\n",
    "                \"top_p\": 0.95,\n",
    "            }\n",
    "        )\n",
    "\n",
    "teacher_model_config = {\n",
    "    \"model_client\": GoogleGenAIClient(api_key=\"<your_api_key>\"),\n",
    "    \"model_kwargs\": {\n",
    "        \"model\": \"gemini-1.5-pro\",\n",
    "        \"temperature\": 0.0,\n",
    "        \"top_p\": 0.99,\n",
    "    },\n",
    "}\n",
    "\n",
    "text_optimizer_model_config = {\n",
    "    \"model_client\": GoogleGenAIClient(api_key=\"<your_api_key>\"),\n",
    "    \"model_kwargs\": {\n",
    "        \"model\": \"gemini-1.5-flash-002\",\n",
    "        \"temperature\": 0.6,\n",
    "        \"top_p\": 0.95,\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GSM8K_Task_Pipeline(adal.Component):\n",
    "    def __init__(self, model_client: adal.ModelClient, model_kwargs: dict):\n",
    "        super().__init__()\n",
    "        system_prompt = adal.Parameter(\n",
    "            data=\"You will answer a reasoning question. Think step by step. The last line of your response should be of the following format: 'Answer: $VALUE' where VALUE is a numerical value.\",\n",
    "            role_desc=\"To give task instruction to the language model in the system prompt\",\n",
    "            requires_opt=True,\n",
    "            param_type=ParameterType.PROMPT,\n",
    "        )\n",
    "\n",
    "        few_shot_demos = adal.Parameter(\n",
    "            data=None,\n",
    "            role_desc=\"To give few shot examples to the language model in the system prompt\",\n",
    "            requires_opt=False,\n",
    "            param_type=ParameterType.DEMOS,\n",
    "        )\n",
    "\n",
    "        self.llm_counter = adal.Generator(\n",
    "            model_client=model_client,\n",
    "            model_kwargs=model_kwargs,\n",
    "            template=FEW_SHOT_TEMPLATE,\n",
    "            prompt_kwargs={\"system_prompt\":system_prompt, \"few_shot_demos\":few_shot_demos},\n",
    "            output_processors=parse_integer_answer,\n",
    "            cache_path=None,\n",
    "            use_cache=False,\n",
    "            name=\"llm_counter\",\n",
    "        )\n",
    "\n",
    "    def call(self, question: str,id: str):\n",
    "        output= self.llm_counter(prompt_kwargs={\"input_str\": question},id=id)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Callable, Dict, Tuple,Any\n",
    "\n",
    "class GSM8K_AdalComponent(adal.AdalComponent):\n",
    "    def __init__(\n",
    "        self,\n",
    "        model_client: adal.ModelClient,\n",
    "        model_kwargs: Dict,\n",
    "    ):\n",
    "        task = GSM8K_Task_Pipeline(model_client=model_client, model_kwargs=model_kwargs)\n",
    "        eval_fn = AnswerMatchAcc(type=\"exact_match\").compute_single_item\n",
    "        loss_fn = adal.EvalFnToTextLoss(\n",
    "            eval_fn=eval_fn,\n",
    "            eval_fn_desc=\"exact_match: 1 if str(y) == str(y_gt) else 0\",\n",
    "            backward_engine=backward_engine\n",
    "        )\n",
    "        super().__init__(task=task, eval_fn=eval_fn, loss_fn=loss_fn)\n",
    "        self.text_optimizer_model_config = text_optimizer_model_config\n",
    "        self.teacher_model_config = teacher_model_config\n",
    "        self.backward_engine = backward_engine\n",
    "\n",
    "    def prepare_task(self, sample: Example):\n",
    "        return self.task.call, {\"question\": sample.question, \"id\": sample.id}\n",
    "\n",
    "    def prepare_eval(self, sample: Example, y_pred: adal.GeneratorOutput) -> float:\n",
    "        y_label = -1\n",
    "        if (y_pred is not None and y_pred.data is not None):  # if y_pred and y_pred.data: might introduce bug when the data is 0\n",
    "            y_label = y_pred.data\n",
    "        y_gt = parse_integer_answer(sample.answer)\n",
    "        return self.eval_fn, {\"y\": y_label, \"y_gt\": y_gt}\n",
    "\n",
    "    def prepare_loss(\n",
    "        self, sample: Example, pred: adal.Parameter\n",
    "    ) -> Tuple[Callable, Dict[str, Any]]:\n",
    "        result=parse_integer_answer(sample.answer)\n",
    "        y_gt = adal.Parameter(\n",
    "            name=\"y_gt\",\n",
    "            data=result,\n",
    "            eval_input=result,\n",
    "            requires_opt=False,\n",
    "        )\n",
    "        pred.eval_input = pred.data\n",
    "        return self.loss_fn, {\"kwargs\": {\"y\": pred, \"y_gt\": y_gt}}\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "adal_component = GSM8K_AdalComponent(\n",
    "        model_client=main_model_client,\n",
    "        model_kwargs=main_model_kwargs,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from adalflow import Trainer\n",
    "train_batch_size=4\n",
    "raw_shots=1\n",
    "bootstrap_shots=1\n",
    "max_steps=12\n",
    "num_workers=4\n",
    "strategy=\"constrained\"\n",
    "debug=False\n",
    "\n",
    "trainer = Trainer(\n",
    "        train_batch_size=train_batch_size,\n",
    "        strategy=strategy,\n",
    "        # max_steps=max_steps,\n",
    "        num_workers=num_workers,\n",
    "        adaltask=adal_component,\n",
    "        raw_shots=raw_shots,\n",
    "        bootstrap_shots=bootstrap_shots,\n",
    "        debug=debug,\n",
    "        weighted_sampling=True,\n",
    "    )\n",
    "trainer.fit(train_dataset=train_dataset, val_dataset=val_dataset, test_dataset=test_dataset, debug=debug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
